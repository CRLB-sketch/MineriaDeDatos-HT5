---
title: "HT05"
date: "2023-03-17"
---
```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# Hoja de Trabajo 05 - Naive Bayes

``` {r echo=FALSE}
library(dplyr)
library(knitr)
library(rpart)       # performing regression trees
library(rsample)     # data splitting 
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
library(caret)       # bagging
library(randomForest)
library(e1071)       # naiveBayes
```

## 1 - Conjuntos de entrenamiento y pruebas pasadas

```{r echo=FALSE}
data <- read.csv("train.csv")
```

### Limpiando los datos
```{r echo=FALSE}
columns_used <- c()
neighborhoodNames <- c("NoRidge", "NridgHt", "StoneBr", "Timber", "Veenker", "Somerst", "ClearCr", "Crawfor", "CollgCr", "Blmngtn", "Gilbert", "NWAmes", "SawyerW", "Mitchel", "NAmes", "NPkVill", "SWISU", "Blueste", "Sawyer", "OldTown", "Edwards", "BrkSide", "BrDale", "IDOTRR", "MeadowV")

for(n in 1:length(neighborhoodNames)) {
  # Variable minuscula para nuestro uso.
  data$neighborhood[data$Neighborhood == neighborhoodNames[n]] <- n
}
columns_used <- append(columns_used, "neighborhood")

hs <- c("1Story", "2Story",	"1.5Fin",	"SLvl", "SFoyer")

for(n in 1:length(hs)) {
  # Variable minuscula para nuestro uso.
  data$houseStyle[data$HouseStyle == hs[n]] <- n
}
columns_used <- append(columns_used, "houseStyle")

 data$houseZone[data$MSZoning == "A"] <- 1
 data$houseZone[data$MSZoning == "C"] <- 2
 data$houseZone[data$MSZoning == "FV"] <- 3
 data$houseZone[data$MSZoning == "I"] <- 4
 data$houseZone[data$MSZoning == "RH"] <- 5
 data$houseZone[data$MSZoning == "RL"] <- 6
 data$houseZone[data$MSZoning == "RP"] <- 7
 data$houseZone[data$MSZoning == "RM"] <- 8
 columns_used <- append(columns_used, "houseZone")

data$houseUtilities[data$Utilities == "AllPub"] <- 1
data$houseUtilities[data$Utilities == "NoSewr"] <- 2
data$houseUtilities[data$Utilities == "NoSeWa"] <- 3
data$houseUtilities[data$Utilities == "ELO"] <- 4
columns_used <- append(columns_used, "houseUtilities")

data$roadAccess[data$Condition1 == "Artery"] <- 1
data$roadAccess[data$Condition1 == "Feedr"] <- 2
data$roadAccess[data$Condition1 == "Norm"] <- 3
data$roadAccess[data$Condition1 == "RRNn"] <- 4
data$roadAccess[data$Condition1 == "RRAn"] <- 5
data$roadAccess[data$Condition1 == "PosN"] <- 6
data$roadAccess[data$Condition1 == "PosA"] <- 7
data$roadAccess[data$Condition1 == "RRNe"] <- 8
data$roadAccess[data$Condition1 == "RRAe"] <- 9
columns_used <- append(columns_used, "roadAccess")

data$remodelated[data$YearBuilt != data$YearRemodAdd] <- 1
data$remodelated[data$YearBuilt == data$YearRemodAdd] <- 0
columns_used <- append(columns_used, "remodelated")

data$roofStyle[data$RoofStyle == "Flat"]  <- 1
data$roofStyle[data$RoofStyle == "Gable"]  <- 2
data$roofStyle[data$RoofStyle == "Gambrel"]  <- 3
data$roofStyle[data$RoofStyle == "Hip"]  <- 4
data$roofStyle[data$RoofStyle == "Mansard"]  <- 5
data$roofStyle[data$RoofStyle == "Shed"]  <- 6
columns_used <- append(columns_used, "roofStyle")

data$roofMaterial[data$RoofMatl == "ClyTile"] <- 1
data$roofMaterial[data$RoofMatl == "CompShg"] <- 2
data$roofMaterial[data$RoofMatl == "Membran"] <- 3
data$roofMaterial[data$RoofMatl == "Metal"] <- 4
data$roofMaterial[data$RoofMatl == "Roll"] <- 5
data$roofMaterial[data$RoofMatl == "Tar&Grv"] <- 6
data$roofMaterial[data$RoofMatl == "WdShake"] <- 7
data$roofMaterial[data$RoofMatl == "WdShngl"] <- 8
columns_used <- append(columns_used, "roofMaterial")

data$overallQuality <- data$OverallQual
columns_used <- append(columns_used, "overallQuality")

data$overallCondition <- data$OverallCond
columns_used <- append(columns_used, "overallCondition")


data$exteriorCondition[data$ExterCond == "Po"] <- 1
data$exteriorCondition[data$ExterCond == "Fa"] <- 2
data$exteriorCondition[data$ExterCond == "TA"] <- 3
data$exteriorCondition[data$ExterCond == "Gd"] <- 4
data$exteriorCondition[data$ExterCond == "Ex"] <- 5
columns_used <- append(columns_used, "exteriorCondition")

data$foundationMaterial[data$Foundation == "BrkTil"] <- 1
data$foundationMaterial[data$Foundation == "CBlock"] <- 2
data$foundationMaterial[data$Foundation == "PConc"] <- 3
data$foundationMaterial[data$Foundation == "Slab"] <- 4
data$foundationMaterial[data$Foundation == "Stone"] <- 5
data$foundationMaterial[data$Foundation == "Wood"] <- 6
columns_used <- append(columns_used, "foundationMaterial")

data$basement[is.na(data$BsmtQual)] <- 0
data$basement[!is.na(data$BsmtQual)] <- 1
columns_used <- append(columns_used, "basement")

data$basementCondition[data$BsmtCond == "Ex"] <- 3
data$basementCondition[data$BsmtCond == "Gd"] <- 2
data$basementCondition[data$BsmtCond != "Ex"] <- 1
data$basementCondition[data$BsmtCond != "Gd"] <- 1
data$basementCondition[is.na(data$BsmtCond)] <- 0
columns_used <- append(columns_used, "basementCondition")

data$fireplace[is.na(data$FireplaceQu)] <- 0
data$fireplace[!is.na(data$FireplaceQu)] <- 1
columns_used <- append(columns_used, "fireplace")

data$garageArea <- data$GarageArea
columns_used <- append(columns_used, "garageArea")

data$pool[is.na(data$PoolQC)] <- 0
data$pool[!is.na(data$PoolQC)] <- 1
columns_used <- append(columns_used, "pool")

data$additionalFeature[is.na(data$MiscFeature)] <- 0
data$additionalFeature[!is.na(data$MiscFeature)] <- 1
columns_used <- append(columns_used, "additionalFeature")

data$livingArea <- data$GrLivArea
columns_used <- append(columns_used, "livingArea")

data$yearBuilt <- data$YearBuilt
columns_used <- append(columns_used, "yearBuilt")


data$salePrice <- data$SalePrice
columns_used <- append(columns_used, "salePrice")

tv <- c("WD", "Oth", "New", "ConLw", "ConLI", "ConLD", "Con", "CWD", "COD")

for(n in 1:length(tv)) {
  # Variable minuscula para nuestro uso.
  data$saleType[data$SaleType == tv[n]] <- n
}
columns_used <- append(columns_used, "saleType")

msz <- c("FV", "RL", "RH", "RM" , "C (all)")

for(n in 1:length(msz)) {
  # Variable minuscula para nuestro uso.
  data$mSZoning[data$MSZoning == msz[n]] <- n
}
columns_used <- append(columns_used, "mSZoning")

clean_data <- subset(data, select = columns_used)
```

Columnas a utilizar (basándonos en el análisis exploratorio de la hoja anterior):
```{r}
print(paste(columns_used,collapse=' '))
```

Un 75% del dataset se usará para entrenar el árbol.
``` {r}
set.seed(5)
expected_result <- clean_data$salePrice
partition <- createDataPartition(y=expected_result,
                                 p=.75,
                                 list=F)
train_set <- clean_data[partition,]
test_set <- clean_data[-partition,]
```

## 2 - Modelo de regresión usando bayes ingenuo
```{r}
colnames(test_set)
```

``` {r}
model_naive_bayes <- naiveBayes(salePrice~., data=train_set)

pred_bayes <- predict(model_naive_bayes, newdata=test_set[,-21])
pred_bayes <- as.numeric(as.character(pred_bayes))
plot(test_set$salePrice, col="red")
points(pred_bayes, col="green")

EMA <- mean(test_set$salePrice-pred_bayes, na.rm = T)
```
Se obtuvo un de: `r EMA`, para el error medio absoluto. Además los valores de predicción se ven bastante apegados a los valores reales.

## 3 - Modelo de clasificacion, variable categórica que hizo con el precio de las casas (barata, media y cara)

Volviendo a usar la variable categorica
```{r}
test_set$economy <- ifelse(test_set$salePrice < 163000, "Economic", ifelse(test_set$salePrice >= 163000 & test_set$salePrice <= 214000, "Average", "Expensive"))
train_set$economy <- ifelse(train_set$salePrice < 163000, "Economic", ifelse(train_set$salePrice >= 163000 & train_set$salePrice <= 214000, "Average", "Expensive"))
```

Implementar modelo de clasificacion
``` {r}
model_clasification <- naiveBayes(economy ~ ., data = train_set)
predictions_clasification <- predictions <- predict(model_clasification, newdata = test_set, type = "class")
confusion_matrix_clasification <- table(predictions_clasification, test_set$economy)
accuracy_clasification <- sum(diag(confusion_matrix_clasification)) / sum(confusion_matrix_clasification)
print(accuracy_clasification)
```

Se obtuvo 1 de presicion, el cual indica que la clasificación es eficiente

## 4 - Utilizar los modelos con el conjunto de prueba y determine la eficiencia del algoritmo

``` {r}
clean_test = na.omit(test_set)

y4_cl <- clean_test[,c("economy")]
y4_cl <- as.numeric(as.factor(y4_cl))
y_pred_4_cl <- predict(model_clasification, newdata = clean_test)
y_pred_4_cl <- as.numeric(as.factor(y_pred_4_cl))
y4_mean_cl <- mean(y4_cl, na.rm = TRUE)
y_pred_4_mean_cl <- mean(y_pred_4_cl, na.rm = TRUE)
difference_cl <- abs(y4_mean_cl - y_pred_4_mean_cl)
```
Para el modelo de clasificación se obtuvo una diferencia de `r difference_cl` entre el promedio de conjuntos de valores reales y predichos lo cual es bastante bajo lo que significa que la predicción se acerca bastante a los valores reales.


## 5 - Analizar los resultados del modelo de regresión
```{r}
y4_reg <- clean_test[,c("salePrice")]
y_pred_4_reg <- predict(model_naive_bayes, clean_test)
y_pred_4_reg <- as.numeric(y_pred_4_reg)
abs_error_4_reg <- abs(mean(y_pred_4_reg - clean_test$salePrice))
```
Para el modelo de regresión se obtuvo para un error absoluto de `r abs_error_4_reg`.



## 6 - Comprar resultados del modelo de regresión lineal y el árbol de regresión


```{r}
colnames(test_set)
```



## 7 - Realizar análisis de la eficiencia del modelo de clasificación usando una matriz de confusión.
```{r}
train_prediction <- predict(model_clasification, newdata = train_set)
test_prediction <- predict(model_clasification, newdata = test_set)
```

### Matriz de confusión para set de entrenamiento
```{r}
confusionMatrix(train_prediction, as.factor(train_set$economy))
```
### Matriz de confusión para set de prueba
```{r}
confusionMatrix(test_prediction, as.factor(test_set$economy))
```



## 8 - Analizar el modelo ¿cree que pueda estar sobre ajustado?

```{r}
train_prediction <- predict(model_clasification, newdata = train_set)
test_prediction <- predict(model_clasification, newdata = test_set)
```

### Matriz de confusión para set de entrenamiento
```{r}
confusionMatrix(train_prediction, as.factor(train_set$economy))
```
### Matriz de confusión para set de prueba
```{r}
confusionMatrix(test_prediction, as.factor(test_set$economy))
```

La accuracy del modelo en el set de prueba es de 0.697 y de 0.73 para el set de entrenamiento. No es mucha la diferencia entre los dos conjuntos de datos. Por lo que podemos descartar que el modelo tenga sobre ajuste.

## 9 - Haga un modelo usando validación cruzada

```{r}
fit_control <- trainControl(method = "cv", number = 2)
cross_model <- train(economy ~ ., data = na.omit(train_set), method = "nb", trControl = fit_control)
```
Realizando predicciones
```{r}
predictions_cross_model <-  predict(cross_model, newdata = test_set)
confusionMatrix(predictions_cross_model, as.factor(na.omit(test_set)$economy))
```

## 10 - Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación) y el modelo de random forest que hizo en la hoja pasada. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?

Tomando en cuenta la matriz de confusión, tenemos una exactitud de 0.8775, mientras que para la hoja anterior utilizando el método de Random Forest se tuvo 0.849. Por lo que este algoritmo es más eficiente para clasificar los valores. Sin embargo, el costo es el tiempo que utiliza dado que con Random Forest el modelo se entrenó más rápido.